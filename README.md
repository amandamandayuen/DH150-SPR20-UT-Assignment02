# DH150 Assignment02: Pilot Usability Test 
### by Amanda Ruan

## Introduction
In this Pilot Usability Testing Assignment, I tested the usability of the mobile app COVID-19Tracker. As shown by its name, this is an app developed by the HealthLynked Corp to provide the public information about the data and spread of COVID-19 worldwide. The app presents WHO confirmed cases and deaths on an interactive Google map and also users’ self-report COVID-19 related conditions. In addition, the app also updates worldwide COVID-19 news and opens up chatgroups for users to communicate. 

The participant of my usability testing is my roommate, and I recorded the screen and her facial expression through ActivePresenter. I conducted the usability test in a quiet room in our apartment. The session lasted for around 30 minutes. I developed three tasks based on heuristic evaluation and guided the participant through the questionnaire and the tasks. 

## Purpose

Users’ interaction with an app during usability testing is valuable as it informs developers potential flaws in app design related to user experience. The purpose of Usability Testing of an app is to see how target users navigate through different features on the app, whether users can search for information they need and understand the information present by the app. Specifically, this usability testing aims to see whether the COVID-19Tracker app is navigable, whether the COVID-19Tracker app presents clear information, and whether a user can find the information he/she needs on the app. 

The heuristic evaluation in the last assignment revealed three main concerns related to the usability of the app:

1.	The “Feed” feature does not use recognition-based design and is less flexible and efficient for users to search or sort news. It provides only COVID-19 news within a short time period, and the news were from a variety of news sources, regions, and were related to different topics. Users cannot search any information by keyword, sort the news based on different categories, or find out what news they have read before. Addressing this concern, I developed task 1 to ask the participant to search for a news related to California government on the “Feed” page. I wanted to understand the participant’s interaction with the inefficiencies and inflexibilities of the “Feed” page. 

2.	The flexibility and efficiency of use and match between the system and the real world related to the “Map” feature. The map page does not provide instructions on how new users can navigate the map, and visual representation of the data is not consistent in matching to COVID-19 data in the real world. For instance, some countries’ data was shown by smaller counties while other countries’ data was only shown by country. To address this concern, I developed task 2 to ask the participants to interact with the map, explore the labels, and whether the participant can identify an inconsistency in the matching between real world data.

3.	The names of some labels could create confusion when users first use the app, and the menu tab for further information and help and documentation could be hard to find. For instance, the app categorizes COVID-19 cases into five labels, and two of them were “Asymptomatic” and “Symptomatic”. Even though the app provides definitions for the two labels, it does not specify the sources of the data within the app. To address this concern, I created task 3 to ask the participant to look for the definition of “Asymptomatic” and also look for information mentioning the sources within the entire app. I wanted to see the participant’s interaction with the app as well as whether the participant was aware of the menu tab that could be used for further help. 

### Link to my online survey:

survey link: https://forms.gle/CiT3wQHkAE1jNgzt6

editable version: https://docs.google.com/forms/d/1J-9A1Xe3VG_xV6jhbmLRx-K2ng3_KZGcS5n-4pARbQs/edit

### Link to my UT video:

video link: 

## Reflection

Overall, the pilot test went smoothly. The setup and the software functioned normally throughout the test. The participant was not confused by the questionnaire and the tasks as she followed the steps smoothly. During the pilot test process, I learned that it was harder to be a moderator as I thought. Specifically, I needed to pay attention on the participant’s interaction with the app, and also figured out the language I used to provide hints or communicate with the participant. I tended to quietly observe the participant’s interaction and was not sure about how much I could give hint to the participant when she was not aware of certain features of the app. It was also interesting to observe that, while the participant’s behaviors indicated that she had little trouble looking for the information she needed during the last task, she did not reflect her struggle during post-questionnaire self-assessment. This makes me realize the importance of both physical observations (video records) and questionnaire-based participant’s self-assessment during the UT process. Both tools allow the UT to capture fully what’s actually going on during the participant’s interaction. One concern related to visibility of system status arose (which I did not think of before), as the participant was confident that she did not miss any information in the app while she was not aware of certain taps and features. In the future, I want to improve my task design, to make the steps flow more smoothly and naturally without giving obvious instructions or hints to the participant. I also want to improve the way I communicate with the participant. For instance, I should develop a script responding a participant’s questions or reacting to a participant’s behaviors to make sure my language choices are consistent.
